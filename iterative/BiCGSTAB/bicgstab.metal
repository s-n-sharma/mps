//BiCGSTAB-specific kernels

#include <metal_stdlib>
#include <metal_atomic>

using namespace metal;

constant int SIMD_WIDTH = 32;
constant int THREADGROUP_SIZE = 256;

kernel void upp(
    device float* p [[buffer(0)]],
    device const float* r [[buffer(1)]],
    device const float* v [[buffer(2)]],
    device const float* scalars [[buffer(3)]],
    constant uint& size,
    uint gid [[ thread_position_in_grid ]]
) {
    //In the future, we should probably figure out a way to fuse the spmv (v = Ap) step with this step to reduce overhead
    //However, not implemented right now :sob:

    threadgroup float rho_prev = scalars[0];
    threadgroup float rho_curr = scalars[1];
    threadgroup float alpha = scalars[2];
    threadgroup float omega = scalars[3];

    if (gid < size) {
        p[gid] = r[gid] + (rho_curr/rho_prev) * (alpha/omega) * (p[gid] - omega*v[gid]);
    }
}
kernel void upalpha_ups(
    device float* s [[buffer(0)]],
    device const float* r [[buffer(1)]],
    device const float* v [[buffer(2)]],
    device float* scalars [[buffer(3)]],
    constant uint& size,
    uint gid [[thread_position_in_grid]]
) {
    //In the future, we should probably figure out a way to fuse the spmv (t = As) step with this step to reduce overhead
    //However, not implemented right now :sob:

    threadgroup float alpha = scalars[1] / scalars[4];

    if (gid < size) {
        s[gid] = r[gid] - alpha * v[gid];
    }

    if (gid == 0) {
        scalars[2] = alpha;
    }

}
kernel void f_dip(
    device const float* s [[buffer(0)]],
    device const float* t [[buffer(1)]],
    device float* scalars [[buffer(2)]],
    constant uint& size,
    uint gid [[thread_position_in_grid]],
    uint tid [[thread_index_in_simdgroup]],
    uint sid [[simdgroup_index_in_threadgroup]],
    uint lid [[thread_position_in_threadgroup]]
) {
    //given t, s compute t * s and t * t

    threadgroup float temp_st[THREADGROUP_SIZE/SIMD_WIDTH];
    threadgroup float temp_tt[THREADGROUP_SIZE/SIMD_WIDTH];
    float prod_st = 0.0;
    float prod_tt = 0.0;
    
    if (lid < (THREADGROUP_SIZE / SIMD_WIDTH)) {
        temp_st[lid] = 0.0f;
        temp_tt[lid] = 0.0f;
    }

    threadgroup_barrier(mem_flags::mem_threadgroup);

    if (gid < size) {
        prod_st = s[gid] * t[gid];
        prod_tt = t[gid] * t[gid];
    }

    float local_sum_st = simd_sum(prod_st);
    float local_sum_tt = simd_sum(prod_tt);

    if (tid == 0) {
        temp_st[sid] = local_sum_st;
        temp_tt[sid] = local_sum_tt;
    }

    threadgroup_barrier(mem_flags::mem_threadgroup);

    //reduction

    if (lid == 0) {
        float thread_group_sum_st = 0.0f;
        float thread_group_sum_tt = 0.0f;

        for (int i = 0; i < THREADGROUP_SIZE/SIMD_WIDTH; i++) {
            thread_group_sum_st += temp_st[i];
            thread_group_sum_tt += temp_tt[i];
        }

        if (thread_group_sum_st != 0.0 && !isnan(thread_group_sum_st)) {
            atomic_fetch_add_explicit((device atomic_float*) &scalars[5], thread_group_sum_st, memory_order_relaxed);
        }

        if (thread_group_sum_tt != 0.0 && !isnan(thread_group_sum_tt)) {
            atomic_fetch_add_explicit((device atomic_float*) &scalars[6], thread_group_sum_tt, memory_order_relaxed);
        }
    }   
}

kernel void f_upomega_upxr_laa(
    device float* x [[buffer(0)]],
    device float* r [[buffer(1)]],
    device const float* p [[buffer(2)]],
    device const float* r_0 [[buffer(3)]],
    device const float* s [[buffer(4)]],
    device const float* t [[buffer(5)]],
    device float* scalars [[buffer(6)]],
    constant uint& size,
    uint gid [[thread_position_in_grid]],
    uint tid [[thread_index_in_simdgroup]],
    uint sid [[simdgroup_index_in_threadgroup]],
    uint lid [[thread_position_in_threadgroup]]
) {
    threadgroup float omega = scalars[5] / scalars[6];
    threadgroup float alpha = scalars[2];

    float micro_rho_sum = 0.0;
    float micro_norm_sum = 0.0;

    threadgroup float temp_norm[THREADGROUP_SIZE/SIMD_WIDTH];
    threadgroup float temp_rho[THREADGROUP_SIZE/SIMD_WIDTH];
    
    if (lid < (THREADGROUP_SIZE / SIMD_WIDTH)) {
        temp_rho[lid] = 0.0f;
        temp_norm[lid] = 0.0f;
    }

    threadgroup_barrier(mem_flags::mem_threadgroup);

    if (gid < size) {
        x[gid] = x[gid] + alpha * p[gid] + omega * s[gid];
        r[gid] = s[gid] - omega * t[gid];

        micro_rho_sum = r_0[gid] * r[gid];
        micro_norm_sum = r[gid] * r[gid];
    }

    float local_rho_sum = simd_sum(micro_rho_sum);
    float local_norm_sum = simd_sum(micro_norm_sum);

    if (tid == 0) {
        temp_norm[sid] = local_norm_sum;
        temp_rho[sid] = local_rho_sum;
    }
    if (gid == 0) {
        scalars[3] = omega;
    }

    threadgroup_barrier(mem_flags::mem_threadgroup);

    //reduction

     if (lid == 0) {
        float thread_group_rho_sum = 0.0f;
        float thread_group_norm_sum = 0.0f;

        for (int i = 0; i < THREADGROUP_SIZE/SIMD_WIDTH; i++) {
            thread_group_rho_sum += temp_rho[i];
            thread_group_norm_sum += temp_norm[i];
        }

        if (thread_group_rho_sum != 0.0 && !isnan(thread_group_rho_sum)) {
            atomic_fetch_add_explicit((device atomic_float*) &scalars[0], thread_group_rho_sum, memory_order_relaxed);
        }

        if (thread_group_norm_sum != 0.0 && !isnan(thread_group_norm_sum)) {
            atomic_fetch_add_explicit((device atomic_float*) &scalars[7], thread_group_norm_sum, memory_order_relaxed);
        }
    }      
}

